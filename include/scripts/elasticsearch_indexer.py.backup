"""
Elasticsearch indexing utilities for Nutriweather Datalake
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any
from elasticsearch import Elasticsearch
import pandas as pd
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ElasticsearchIndexer:
    """
    Handles indexing of nutritional and weather data into Elasticsearch
    """
    
    def __init__(self, 
                 host: str = "https://es01:9200",  # Use Docker service name
                 username: str = "elastic",
                 password: str = "elastic",
                 ca_cert_path: str = None):        """
        Initialize Elasticsearch client with fallback options
        
        Args:
            host: Elasticsearch host URL
            username: Username for authentication
            password: Password for authentication
            ca_cert_path: Path to CA certificate for SSL verification
        """
        # Try HTTPS first, then HTTP as fallback
        connection_attempts = [
            {
                "hosts": [host],
                "basic_auth": (username, password),
                "verify_certs": False,
                "ssl_show_warn": False,
                "timeout": 30,
                "max_retries": 2,
                "retry_on_timeout": True,
                "request_timeout": 30
            }
        ]
        
        # Add HTTP fallback if HTTPS fails
        if host.startswith("https://"):
            http_host = host.replace("https://", "http://")
            connection_attempts.append({
                "hosts": [http_host],
                "basic_auth": (username, password),
                "timeout": 30,
                "max_retries": 2,
                "retry_on_timeout": True,
                "request_timeout": 30
            })
        
        last_error = None
        for i, config in enumerate(connection_attempts):
            try:
                logger.info(f"Attempting Elasticsearch connection {i+1}/{len(connection_attempts)}: {config['hosts'][0]}")
                self.es = Elasticsearch(**config)
                
                # Test connection
                if self.es.ping():
                    logger.info(f"✅ Successfully connected to Elasticsearch at {config['hosts'][0]}")
                    return
                else:
                    logger.warning(f"⚠️ Connection attempt {i+1} failed: ping unsuccessful")
                    
            except Exception as e:
                last_error = e
                logger.warning(f"⚠️ Connection attempt {i+1} failed: {e}")
                continue
        
        # If we get here, all attempts failed
        logger.error("❌ All connection attempts failed")
        raise Exception(f"Elasticsearch connection failed: {last_error}")
    
    def create_index_template(self, index_name: str, mapping: Dict[str, Any]):
        """
        Create an index template with proper mappings
        
        Args:
            index_name: Name of the index
            mapping: Elasticsearch mapping configuration
        """
        try:
            template_body = {
                "index_patterns": [f"{index_name}-*"],
                "template": {
                    "mappings": mapping,
                    "settings": {
                        "number_of_shards": 1,
                        "number_of_replicas": 0
                    }
                }
            }
            
            self.es.indices.put_index_template(
                name=f"{index_name}-template",
                body=template_body
            )
            logger.info(f"Created index template for {index_name}")
            
        except Exception as e:
            logger.error(f"Error creating index template: {e}")
            raise
    
    def index_meals_data(self, data_path: str):
        """
        Index meals data from formatted JSON files
        
        Args:
            data_path: Path to the formatted meals data directory
        """
        meals_mapping = {
            "properties": {
                "@timestamp": {"type": "date"},
                "meal_id": {"type": "keyword"},
                "meal_name": {"type": "text", "analyzer": "standard"},
                "category": {"type": "keyword"},
                "area": {"type": "keyword"},
                "instructions": {"type": "text"},
                "ingredients": {
                    "type": "nested",
                    "properties": {
                        "name": {"type": "keyword"},
                        "measure": {"type": "text"}
                    }
                },
                "tags": {"type": "keyword"},
                "youtube_url": {"type": "keyword"},
                "source_url": {"type": "keyword"},
                "image_url": {"type": "keyword"},
                "nutrition": {
                    "properties": {
                        "calories": {"type": "float"},
                        "protein": {"type": "float"},
                        "carbs": {"type": "float"},
                        "fat": {"type": "float"}
                    }
                }
            }
        }
        
        # Create index template
        self.create_index_template("nutriweather-meals", meals_mapping)
        
        # Index the data
        self._index_json_files(data_path, "nutriweather-meals", "meals")
    
    def index_weather_data(self, data_path: str):
        """
        Index weather data from formatted JSON files
        
        Args:
            data_path: Path to the formatted weather data directory
        """
        weather_mapping = {
            "properties": {
                "@timestamp": {"type": "date"},
                "location": {
                    "properties": {
                        "latitude": {"type": "float"},
                        "longitude": {"type": "float"},
                        "timezone": {"type": "keyword"},
                        "elevation": {"type": "float"}
                    }
                },
                "current": {
                    "properties": {
                        "time": {"type": "date"},
                        "temperature_2m": {"type": "float"},
                        "relative_humidity_2m": {"type": "float"},
                        "apparent_temperature": {"type": "float"},
                        "precipitation": {"type": "float"},
                        "weather_code": {"type": "integer"},
                        "cloud_cover": {"type": "float"},
                        "wind_speed_10m": {"type": "float"},
                        "wind_direction_10m": {"type": "float"}
                    }
                },
                "hourly": {
                    "type": "nested",
                    "properties": {
                        "time": {"type": "date"},
                        "temperature_2m": {"type": "float"},
                        "relative_humidity_2m": {"type": "float"},
                        "precipitation": {"type": "float"},
                        "weather_code": {"type": "integer"}
                    }
                }
            }
        }
        
        # Create index template
        self.create_index_template("nutriweather-weather", weather_mapping)
        
        # Index the data
        self._index_json_files(data_path, "nutriweather-weather", "weather")
    
    def index_usage_data(self, data_path: str):
        """
        Index usage data from JSON files
        
        Args:
            data_path: Path to the usage data directory
        """
        usage_mapping = {
            "properties": {
                "@timestamp": {"type": "date"},
                "data_type": {"type": "keyword"},
                "endpoint": {"type": "keyword"},
                "location": {
                    "properties": {
                        "latitude": {"type": "float"},
                        "longitude": {"type": "float"},
                        "city": {"type": "keyword"},
                        "country": {"type": "keyword"}
                    }
                },
                "response_time_ms": {"type": "integer"},
                "status_code": {"type": "integer"},
                "data_size_bytes": {"type": "integer"},
                "user_agent": {"type": "keyword"},
                "search_term": {"type": "text", "analyzer": "standard"},
                "category": {"type": "keyword"},
                "results_count": {"type": "integer"},
                "process_type": {"type": "keyword"},
                "input_records": {"type": "integer"},
                "output_records": {"type": "integer"},
                "processing_time_ms": {"type": "integer"},
                "memory_usage_mb": {"type": "integer"},
                "status": {"type": "keyword"}
            }
        }
        
        # Create index template
        self.create_index_template("nutriweather-usage", usage_mapping)
        
        # Index the data
        self._index_json_files(data_path, "nutriweather-usage", "usage")
    
    def _index_json_files(self, data_path: str, index_prefix: str, data_type: str):
        """
        Index JSON files from a directory
        
        Args:
            data_path: Path to data directory
            index_prefix: Elasticsearch index prefix
            data_type: Type of data being indexed
        """
        if not os.path.exists(data_path):
            logger.warning(f"Data path does not exist: {data_path}")
            return
        
        indexed_count = 0
        
        for filename in os.listdir(data_path):
            if filename.endswith('.json'):
                file_path = os.path.join(data_path, filename)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # Create index name with date
                    date_str = datetime.now().strftime('%Y-%m-%d')
                    index_name = f"{index_prefix}-{date_str}"
                    
                    # Add timestamp if not present
                    if isinstance(data, list):
                        for item in data:
                            if '@timestamp' not in item:
                                item['@timestamp'] = datetime.now().isoformat()
                    elif isinstance(data, dict):
                        if '@timestamp' not in data:
                            data['@timestamp'] = datetime.now().isoformat()
                        data = [data]  # Convert to list for bulk indexing
                    
                    # Bulk index the data
                    self._bulk_index(data, index_name)
                    indexed_count += len(data) if isinstance(data, list) else 1
                    
                    logger.info(f"Indexed {filename} to {index_name}")
                    
                except Exception as e:
                    logger.error(f"Error indexing {filename}: {e}")
        
        logger.info(f"Total {data_type} documents indexed: {indexed_count}")
    
    def _bulk_index(self, documents: List[Dict], index_name: str):
        """
        Bulk index documents to Elasticsearch
        
        Args:
            documents: List of documents to index
            index_name: Target index name
        """
        try:
            from elasticsearch.helpers import bulk
            
            actions = []
            for doc in documents:
                action = {
                    "_index": index_name,
                    "_source": doc
                }
                actions.append(action)
            
            bulk(self.es, actions, chunk_size=500, request_timeout=60)
            
        except Exception as e:
            logger.error(f"Error during bulk indexing: {e}")
            raise
    
    def create_sample_dashboard_data(self, output_path: str):
        """
        Create sample data for Kibana dashboards
        
        Args:
            output_path: Path to save sample data
        """
        # Sample nutritional analytics data
        sample_data = [
            {
                "@timestamp": datetime.now().isoformat(),
                "meal_category": "Breakfast",
                "avg_calories": 450,
                "avg_protein": 15,
                "avg_carbs": 60,
                "meal_count": 25,
                "popular_ingredients": ["eggs", "bread", "milk", "butter"]
            },
            {
                "@timestamp": datetime.now().isoformat(),
                "meal_category": "Lunch",
                "avg_calories": 650,
                "avg_protein": 35,
                "avg_carbs": 45,
                "meal_count": 40,
                "popular_ingredients": ["chicken", "rice", "vegetables", "olive oil"]
            },
            {
                "@timestamp": datetime.now().isoformat(),
                "meal_category": "Dinner",
                "avg_calories": 750,
                "avg_protein": 40,
                "avg_carbs": 50,
                "meal_count": 35,
                "popular_ingredients": ["beef", "pasta", "tomatoes", "cheese"]
            }
        ]
        
        os.makedirs(output_path, exist_ok=True)
        
        with open(os.path.join(output_path, 'nutrition_analytics.json'), 'w') as f:
            json.dump(sample_data, f, indent=2)
        
        logger.info(f"Created sample dashboard data in {output_path}")


def main():
    """
    Example usage of the ElasticsearchIndexer
    """
    # Initialize indexer
    indexer = ElasticsearchIndexer()
    
    # Create sample data for testing
    usage_path = "/usr/local/airflow/include/usage"
    indexer.create_sample_dashboard_data(usage_path)
    
    # Index existing formatted data
    formatted_path = "/usr/local/airflow/include/formatted"
    
    # Index weather data if available
    weather_path = os.path.join(formatted_path, "weather")
    if os.path.exists(weather_path):
        indexer.index_weather_data(weather_path)
    
    # Index meals data if available
    meals_path = os.path.join(formatted_path, "meals")
    if os.path.exists(meals_path):
        indexer.index_meals_data(meals_path)
    
    # Index usage data if available
    if os.path.exists(usage_path):
        indexer.index_usage_data(usage_path)


if __name__ == "__main__":
    main()
