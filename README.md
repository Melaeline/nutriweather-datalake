# NutriWeather Data Lake

A comprehensive data processing pipeline that combines nutritional meal data with weather information to enable cross-domain analytics for agricultural and dietary insights.

## ğŸ—ï¸ Architecture Overview

The NutriWeather Data Lake consists of three main processing stages:

1. **Data Ingestion & Formatting** - Raw data collection and standardization
2. **Data Merging** - Combining meal and weather datasets
3. **Analytics & Insights** - Cross-domain analysis capabilities

```
Raw Data Sources
â”œâ”€â”€ TheMealDB API (Meal Data)
â””â”€â”€ Open-Meteo API (Weather Data)
       â†“
Formatting Layer
â”œâ”€â”€ format_meals_dag.py
â””â”€â”€ format_weather_dag.py
       â†“
Merge Layer
â””â”€â”€ merge_formatted_dag.py
       â†“
Analytics Layer
â””â”€â”€ Enhanced meal-weather datasets
```

## ğŸ“ Project Structure

```
nutriweather-datalake/
â”œâ”€â”€ dags/                           # Airflow DAG definitions
â”‚   â”œâ”€â”€ format_meals_dag.py        # Meal data formatting pipeline
â”‚   â”œâ”€â”€ format_weather_dag.py      # Weather data formatting pipeline
â”‚   â””â”€â”€ merge_formatted_dag.py     # Data merging pipeline
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ scripts/                   # Processing scripts
â”‚   â”‚   â”œâ”€â”€ format_meals.py       # Meal data formatting logic
â”‚   â”‚   â”œâ”€â”€ format_weather.py     # Weather data formatting logic
â”‚   â”‚   â””â”€â”€ merge_formatted.py    # Data merging logic
â”‚   â”œâ”€â”€ raw/                      # Raw data storage
â”‚   â”‚   â”œâ”€â”€ meals/                # Raw meal JSON files
â”‚   â”‚   â””â”€â”€ weather/              # Raw weather JSON files
â”‚   â”œâ”€â”€ formatted/                # Processed data storage
â”‚   â”‚   â”œâ”€â”€ meals/                # Formatted meal Parquet files
â”‚   â”‚   â”œâ”€â”€ weather/              # Formatted weather JSON files
â”‚   â”‚   â””â”€â”€ merged/               # Merged analytical datasets
â”‚   â””â”€â”€ logs/                     # Processing logs
â””â”€â”€ README.md                     # This file
```

## ğŸš€ Getting Started

### Prerequisites

- Apache Airflow 2.x
- Python 3.8+
- Apache Spark (for data processing)
- Required Python packages:
  - `pyspark`
  - `pandas`
  - `requests`

### Installation

1. Clone the repository
2. Install dependencies
3. Configure Airflow to point to the `dags/` directory
4. Start the Airflow scheduler and webserver

### Running the Pipeline

The data processing pipeline consists of three sequential DAGs:

1. **Format Meals DAG** (`format_meals_dag`)
   - Fetches meal data from TheMealDB API
   - Standardizes and enriches meal information
   - Outputs: Parquet files in `include/formatted/meals/`

2. **Format Weather DAG** (`format_weather_dag`)
   - Fetches weather data from Open-Meteo API
   - Processes current and hourly weather information
   - Outputs: JSON files in `include/formatted/weather/`

3. **Merge Formatted DAG** (`merge_formatted_dag`)
   - Combines meal and weather datasets
   - Creates enhanced analytical datasets with cross-domain insights
   - Outputs: JSON files in `include/formatted/merged/`

## ğŸ“Š Data Schema

### Meal Data Fields
- `meal_id`: Unique identifier
- `meal_name`: Recipe name
- `category`: Food category (e.g., Dessert, Chicken)
- `region`: Cuisine origin
- `ingredients`: Ingredient list with quantities
- `instructions`: Cooking steps
- `preparation_time`: Estimated cooking time
- `temperature`: Recommended serving temperature
- `tags`: Recipe tags

### Weather Data Fields
- `location_name`: Geographic location
- `current_temperature`: Real-time temperature
- `humidity`: Current humidity percentage
- `wind_speed`: Wind speed measurement
- `hourly_weather`: 24-hour temperature history

### Merged Data Features
- **Temperature Matching**: Compares meal serving temperature with current weather
- **Weather Recommendations**: Suggests meal types based on weather conditions
- **Seasonal Analysis**: Enables correlation between weather patterns and food preferences

## ğŸ”§ Configuration

### Environment Variables
- `AIRFLOW_HOME`: Airflow installation directory
- `SPARK_HOME`: Spark installation directory (if using local Spark)

### API Endpoints
- **TheMealDB**: `https://www.themealdb.com/api/json/v1/1/`
- **Open-Meteo**: `https://api.open-meteo.com/v1/forecast`

## ğŸ“ˆ Analytics Use Cases

1. **Seasonal Food Trends**: Analyze correlation between weather patterns and meal preferences
2. **Regional Cuisine Analysis**: Compare food choices across different climates
3. **Temperature-Based Recommendations**: Suggest appropriate meals based on current weather
4. **Agricultural Insights**: Correlate weather conditions with ingredient availability

## ğŸ” Monitoring & Logging

- All processing steps are logged with timestamps
- Failed runs include detailed error information
- Data quality metrics are tracked throughout the pipeline
- Airflow UI provides visual monitoring of DAG runs

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ”— External Resources

- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [TheMealDB API](https://www.themealdb.com/api.php)
- [Open-Meteo API](https://open-meteo.com/en/docs)
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)